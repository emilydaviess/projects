# -*- coding: utf-8 -*-
"""01_pytorch.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1utrDz_8XVDMtyQgctBr6ybjNwx2bA73D
"""

import torch
import torchvision
import torchvision.transforms as transforms

torch.cuda.is_available() # check if cuda is available, if false (default), we'll swicth over to GPU

device = 'cuda:0' if torch.cuda.is_available() else 'cpu'
device

transform = transforms.ToTensor()
batch_size=8

trainset = torchvision.datasets.FashionMNIST(
    root="./data",
    train=True,
    download=True,
    transform=transform
)
testset = torchvision.datasets.FashionMNIST(
    root="./data",
    train=False,
    download=True,
    transform=transform
)

classes = (
    "T-shirt/top", "Trousers/pants", "Pullover shirt", "Dress",
    "Coat", "Sandal", "Shirt", "Sneaker", "Bag","Ankle boot"
)

# lets learn a bit about the Fashion MNIST dataset

train_iter = iter(trainset)
image, label = next(train_iter)
image.shape, label
# we'll see that the shape of the first image is (torch.Size([1, 28, 28]), 9)
# this means the image is of shape 1,28,28 and the claffication is index 9 (ankle boot)

torch.min(image).item(), torch.max(image).item()
# this show the pixels in the image are between 0.0 and 1.0 (min,max)

import matplotlib.pyplot as plt
import numpy as np

np_img = image.numpy() # convert from pytorch tensor to numpy tensor to plot using matplotlib
print(classes[label]) # classes is out list of labels above, using classes[label] i.e. classes[9] will return ankle boot
plt.imshow(np_img.reshape(28,28,1)) # slight reshape as numpy uses this shape

len(trainset), len(testset)

# split the trainset into a trainset & validation test
trainset,valset = torch.utils.data.random_split(trainset, [50000,10000])
len(trainset),len(valset),len(testset)

print(f'Number of batches in the training set: {int(50000/batch_size)}')

print(f'Number of batches in the validation set: {int(10000/batch_size)}')

print(f'Number of batches in the test set: {int(10000/batch_size)}')

type(trainset)

# in pytorch we don't iterate over a dataset, we wrap them in a dataLoader first
trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)
valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False, num_workers=2) # no need to shuffle as we're just evaluating
testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)

import torch.nn as nn
import torch.nn.functional as F

# we made our models (neural networks) as classes when using torch
class NeuralNet(nn.Module): # you can call the class whatever you like
  def __init__(self):
    super().__init__()
    # create your layers for our CNN (convolutional NN)
    # store the layers inside of self, giving the first layer the name of conv1
    # conv1 is a 2 dimensional convolution, and in_channels is 1 because (torch.Size([1, 28, 28]), 9) where channels=1 (greyscale)
    # out_channels = 256 is however much depth we want to convert it to.. in this case 256 filters which are of size 3x3 window (kernel_size=3)
    self.conv1 = nn.Conv2d(in_channels=1, out_channels=256, kernel_size=3)
    self.pool1 = nn.MaxPool2d(2,2) # often accompanying a convolution layer is a maxpool layer
    self.conv2 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3)
    self.pool2 = nn.MaxPool2d(2,2)
    self.conv3 = nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=2)
    self.pool3 = nn.MaxPool2d(2,2)

    # now our image is really small, lets flatten in out into a vector
    self.flatten = nn.Flatten() # streches it out into massive vector torch.Size([8, 4096])
    # now we can do normal linear layer like a fully connect NN

    self.fc1 = nn.Linear(in_features=4096, out_features=1024) # which will gives us torch.Size([8, 1024])
    # add dropout layers
    self.drop1 = nn.Dropout(p=0.3) # give each of the 1024 values to dropout or turn to 0 (good for overfitting - doesn't allow model to rely on samae pattern everytime)
    self.fc2 = nn.Linear(in_features=1024, out_features=1024) # which will gives us torch.Size([8, 1024])
    # add dropout layers
    self.drop2 = nn.Dropout(p=0.3) # give each of the 1024 values to dropout or turn to 0 (good for overfitting - doesn't allow model to rely on samae pattern everytime)

    # add output layer which needs to be linear layer without dropout and needs to end in 10 values (10 classes)

    self.out = nn.Linear(in_features=1024, out_features=10) # torch.Size([8, 10])


  # invoking these layers
  # x is the batch of layers, or whatever we throw into it
  def forward(self, x):
    # telling the network what to do
    # run our batch of layers through the convolution layer which wil return 256,26,26 tensor
    x = F.relu(self.conv1(x)) # apply a relu function to our CNN
    # so, the output tensor shape after applying conv1 will be (batch_size, 256, 26, 26).
    # (there are specific formulas to calculate the output shape)
    x = self.pool1(x) # keep building up x
    x = F.relu(self.conv2(x))
    x = self.pool2(x)
    x = F.relu(self.conv3(x))
    x = self.pool3(x)

    x = self.flatten(x)
    x = F.relu(self.fc1(x)) # apply relu to fully connected layer also
    x = self.drop1(x)
    x = F.relu(self.fc2(x))
    x = self.drop2(x)
    x = self.out(x)

    return x

# lets instaniate our network
net = NeuralNet()
net.to(device)

for i, data in enumerate(trainloader):
  inputs, labels = data[0].to(device), data[1].to(device)
  print(f'input shape: {inputs.shape}')
  print(f'after network shape: {net(inputs).shape}')
  break

# now lets figure out what optimisers and hypers we should be using for our model
import torch.optim as optim

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(net.parameters(), lr=0.0001)

def train_one_epoch():
  net.train(True)

  running_loss = 0.0
  running_accuracy = 0.0

  for batch_index, data in enumerate(trainloader):
    inputs, labels = data[0].to(device), data[1].to(device)
    # neural networks learn through backwards propagation
    # which looks at the model params gradient or derivative in re. to the loss function
    optimizer.zero_grad() # resets gradients (weights) to 0
    # get the outputs of the model
    outputs = net(inputs) # shape [batch_size,10] -> [8,10]
    # lets calc how many correct predictions our models got for each batch
    correct = torch.sum(labels == torch.argmax(outputs,dim=1)).item()
    running_accuracy += correct / batch_size

    # now lets actually train our model

    loss = criterion(outputs, labels)
    running_loss += loss.item()
    loss.backward() # back prop - goes backwards and updates the gradients to hopefully decrease the loss on the next batch
    optimizer.step()

    if batch_index % 500 == 499: # print every 500 batches
      avg_loss_accross_batches = running_loss / 500 # average loss across the batches
      avg_acc_accross_batches = (running_accuracy / 500) * 100
      print('Batch {0}, Loss {1:3f}, Accuracy {2:1f}%'.format(
          batch_index+1, avg_loss_accross_batches,avg_acc_accross_batches
      ))

      running_loss = 0.0 # set back to 0
      running_accuracy = 0.0

def validate_one_epoch():
    net.train(False) # validation mode
    running_loss = 0.0
    running_accuracy = 0.0

    for i, data in enumerate(valloader):
        inputs, labels = data[0].to(device), data[1].to(device)

        with torch.no_grad(): # don't worry about calc gradients - we only use that to train the model
            outputs = net(inputs) # shape: [batch_size, 10]
            correct = torch.sum(labels == torch.argmax(outputs, dim=1)).item()
            running_accuracy += correct / batch_size
            loss = criterion(outputs, labels) # One number, the average batch loss
            running_loss += loss.item()

    avg_loss_across_batches = running_loss / len(valloader)
    avg_acc_across_batches = (running_accuracy / len(valloader)) * 100

    print('Val Loss: {0:.3f}, Val Accuracy: {1:.1f}%'.format(avg_loss_across_batches,
                                                            avg_acc_across_batches))
    print('***************************************************')
    print()

def test_one_epoch():
    net.train(False) # test mode
    running_loss = 0.0
    running_accuracy = 0.0

    for i, data in enumerate(testloader):
        inputs, labels = data[0].to(device), data[1].to(device)

        with torch.no_grad(): # don't worry about calc gradients - we only use that to train the model
            outputs = net(inputs) # shape: [batch_size, 10]
            correct = torch.sum(labels == torch.argmax(outputs, dim=1)).item()
            running_accuracy += correct / batch_size
            loss = criterion(outputs, labels) # One number, the average batch loss
            running_loss += loss.item()

    avg_loss_across_batches = running_loss / len(valloader)
    avg_acc_across_batches = (running_accuracy / len(valloader)) * 100

    print('Test Loss: {0:.3f}, Test Accuracy: {1:.1f}%'.format(avg_loss_across_batches,
                                                            avg_acc_across_batches))
    print('***************************************************')
    print()

# lets write the training loop - this is handled for us in tensorflow, but we have to write it out in pytorch

num_epochs = 10

for epoch_index in range(num_epochs):
  print(f'Epoch: {epoch_index + 1}\n')

  train_one_epoch()
  validate_one_epoch()
  test_one_epoch()

print("Finished Training")